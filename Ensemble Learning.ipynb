{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f43c7d67-c38d-433c-b249-b34649a6456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from keras import layers\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout, Concatenate, Input\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3, DenseNet121\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from sklearn.metrics import classification_report, f1_score, roc_curve, auc\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, save_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4f4dd43-f7ee-4553-95ee-1ae4dda3d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a84ddd8a-2ac7-4a3f-992b-3e1b4595b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e916d97-4ef1-4666-9a69-f15b1ccbf743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_built_with_cuda())\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3664f31b-b6ce-4962-bee8-994eb1378a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the dataset filename:  Needs Respray\n"
     ]
    }
   ],
   "source": [
    "image_dataset_folder = 'Berrijam Datasets/' #\n",
    "dataset_file = input(\"Enter the dataset filename: \")\n",
    "if dataset_file == \"Needs Respray\":\n",
    "    folder = zipfile.ZipFile(image_dataset_folder + \"Data - Needs Respray - 2024-03-26.zip\", \"r\")\n",
    "    folder.extractall()\n",
    "    folder.close()\n",
    "    dataset_dir = \"Data - Needs Respray - 2024-03-26\"\n",
    "elif dataset_file == \"Is Epic Intro\":\n",
    "    folder = zipfile.ZipFile(image_dataset_folder + \"Data - Is Epic Intro 2024-03-25.zip\", \"r\")\n",
    "    folder.extractall()\n",
    "    folder.close()\n",
    "    dataset_dir = \"Data - Is Epic Intro 2024-03-25\"\n",
    "elif data_file == \"Is GenAI\":\n",
    "    folder = zipfile.ZipFile(image_dataset_folder + \"Data - Is GenAI - 2024-03-25.zip\", \"r\")\n",
    "    folder.extractall()\n",
    "    folder.close()\n",
    "    dataset_dir = \"Data - Is GenAI - 2024-03-25\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ca647ea-c486-45f8-adf5-aad53198c6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: paver weeds - 03.png\n",
      "Min pixel value: 0\n",
      "Max pixel value: 255\n",
      "\n",
      "paver weeds - 03.png has been updated and saved.\n",
      "\n",
      "Image: paver weeds - 09.png\n",
      "Min pixel value: 0\n",
      "Max pixel value: 255\n",
      "\n",
      "paver weeds - 09.png has been updated and saved.\n",
      "\n",
      "Image: paver weeds - 17.png\n",
      "Min pixel value: 0\n",
      "Max pixel value: 255\n",
      "\n",
      "paver weeds - 17.png has been updated and saved.\n",
      "\n",
      "Image: paver weeds - 25.png\n",
      "Min pixel value: 0\n",
      "Max pixel value: 255\n",
      "\n",
      "paver weeds - 25.png has been updated and saved.\n",
      "\n",
      "Image: paver weeds - 32.png\n",
      "Min pixel value: 0\n",
      "Max pixel value: 255\n",
      "\n",
      "paver weeds - 32.png has been updated and saved.\n",
      "\n",
      "Image: paver weeds - 36.png\n",
      "Min pixel value: 0\n",
      "Max pixel value: 255\n",
      "\n",
      "paver weeds - 36.png has been updated and saved.\n",
      "\n",
      "Image: paver weeds - 43.png\n",
      "Min pixel value: 0\n",
      "Max pixel value: 255\n",
      "\n",
      "paver weeds - 43.png has been updated and saved.\n",
      "\n",
      "Image: paver weeds - 47.png\n",
      "Min pixel value: 0\n",
      "Max pixel value: 255\n",
      "\n",
      "paver weeds - 47.png has been updated and saved.\n",
      "\n",
      "Image: paver weeds - 59.png\n",
      "Min pixel value: 0\n",
      "Max pixel value: 255\n",
      "\n",
      "paver weeds - 59.png has been updated and saved.\n",
      "\n",
      "Image: paver weeds - 63.png\n",
      "Min pixel value: 0\n",
      "Max pixel value: 255\n",
      "\n",
      "paver weeds - 63.png has been updated and saved.\n",
      "\n",
      "Image: paver weeds - 77.png\n",
      "Min pixel value: 0\n",
      "Max pixel value: 255\n",
      "\n",
      "paver weeds - 77.png has been updated and saved.\n",
      "\n",
      "Image: paver weeds - 85.png\n",
      "Min pixel value: 0\n",
      "Max pixel value: 255\n",
      "\n",
      "paver weeds - 85.png has been updated and saved.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(dataset_dir):\n",
    "    if filename.endswith('g'):\n",
    "        img_path = os.path.join(dataset_dir, filename)\n",
    "        img = Image.open(img_path)\n",
    "        img_array = np.array(img)\n",
    "        img_array = (img_array / np.max(img_array)) * 255\n",
    "        img_array = img_array.astype(np.uint8)\n",
    "        \n",
    "        print(f\"Image: {filename}\")\n",
    "        \n",
    "        print(f\"Min pixel value: {np.min(img_array)}\")\n",
    "        print(f\"Max pixel value: {np.max(img_array)}\\n\")\n",
    "\n",
    "        img = Image.fromarray(img_array)\n",
    "        img.save(img_path)\n",
    "        print(f\"{filename} has been updated and saved.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "186cba4d-d54a-4e3f-9aeb-674c27885ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(dataset_dir):\n",
    "    if filename.endswith('v'):\n",
    "        csv_file = os.path.join(dataset_dir, filename)\n",
    "        \n",
    "Labels = pd.read_csv(csv_file)\n",
    "columns = list(Labels.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bac388fe-3b14-4cc0-9685-8aca8bf02745",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(dataset_dir):\n",
    "    if filename.endswith('v'):\n",
    "        csv_file = os.path.join(dataset_dir, filename)\n",
    "        \n",
    "Labels = pd.read_csv(csv_file)\n",
    "columns = list(Labels.columns)\n",
    "label_names = Labels.iloc[:, 0]\n",
    "expanded_labels = pd.get_dummies(Labels[columns[1]])\n",
    "expanded_labels = expanded_labels.astype('bool')\n",
    "frames = [label_names, expanded_labels]\n",
    "df = pd.concat(frames, axis = 1)\n",
    "folder_names = Labels[columns[1]].unique()\n",
    "\n",
    "copy_from = f\"{dataset_dir}/\"\n",
    "copy_to = f'Images_{dataset_dir[7:-13]}/'\n",
    "\n",
    "if os.path.exists(f'Images_{dataset_dir[7:-13]}') == False:\n",
    "    os.mkdir(f'Images_{dataset_dir[7:-13]}')\n",
    "    \n",
    "if os.path.exists(f'{copy_to}Train') == False:\n",
    "    os.mkdir(f'{copy_to}Train')\n",
    "\n",
    "if os.path.exists(f'{copy_to}Test') == False:\n",
    "    os.mkdir(f'{copy_to}Test')\n",
    "\n",
    "for name in folder_names:\n",
    "    if os.path.exists(copy_to + 'Train/' + name) == False:\n",
    "        os.mkdir(copy_to + 'Train/' + name)\n",
    "    if os.path.exists(copy_to + 'Test/' + name) == False:\n",
    "        os.mkdir(copy_to + 'Test/' + name)\n",
    "\n",
    "\n",
    "for name in folder_names:\n",
    "    files = df.Filename[df[name] == True]\n",
    "    num_samples = len(files)\n",
    "    num_train_samples = round(num_samples * 0.8)\n",
    "    i = 0\n",
    "    for f in files:\n",
    "        path_from = copy_from + f\n",
    "        if i < num_train_samples:\n",
    "            path_to = copy_to + 'Train/' + name + '/' + f\n",
    "        else:\n",
    "            path_to = copy_to + 'Test/' + name + '/' + f\n",
    "        shutil.copyfile(path_from, path_to)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84fa1d3f-d81a-4c41-8165-5e82ad626015",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 900\n",
    "IMAGE_WIDTH = 1200\n",
    "\n",
    "# Define the augmentation layers\n",
    "data_augmentation_layers = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomTranslation(0.4, 0.4),\n",
    "    tf.keras.layers.RandomZoom(0.3),\n",
    "    tf.keras.layers.GaussianNoise(30)\n",
    "])\n",
    "\n",
    "def augment_and_resize(image):\n",
    "    # Apply augmentations and then resize\n",
    "    augmented = data_augmentation_layers(image, training=True)\n",
    "    resized = tf.image.resize(augmented, [IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "    return resized\n",
    "    \n",
    "def load_and_preprocess_image(file_path):\n",
    "    # Load, decode, and preprocess the image\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [IMAGE_HEIGHT, IMAGE_WIDTH]) \n",
    "    image = tf.reshape(image, [IMAGE_HEIGHT, IMAGE_WIDTH, 3])\n",
    "    return image\n",
    "\n",
    "def generate_multiple_augmented_samples(image, num_samples):\n",
    "    # Generate 10 augmented samples for a single image\n",
    "    return tf.data.Dataset.from_tensors(image).repeat(num_samples).map(\n",
    "        augment_and_resize, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "def augment_and_save_dataset(image_dir, save_dir, num_samples=10):\n",
    "    classes = os.listdir(image_dir)\n",
    "    for class_name in classes:\n",
    "        class_path = os.path.join(image_dir, class_name)\n",
    "        save_class_path = os.path.join(save_dir, class_name)\n",
    "        os.makedirs(save_class_path, exist_ok=True)\n",
    "\n",
    "        dataset = tf.data.Dataset.list_files(os.path.join(class_path, '*g'), shuffle=False)\n",
    "        dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        \n",
    "        # Use flat_map to apply the generate_multiple_augmented_samples function with num_samples\n",
    "        dataset = dataset.flat_map(lambda image: generate_multiple_augmented_samples(image, num_samples))\n",
    "        \n",
    "        # Batch and save images\n",
    "        dataset = dataset.batch(1)  # Batch each image individually if saving separately\n",
    "        i = 0  # Reset counter for each class\n",
    "        for batch in dataset:\n",
    "            save_path = os.path.join(save_class_path, f\"aug_{class_name}_{i}.png\")\n",
    "            tf.keras.utils.save_img(save_path, batch[0].numpy())\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "543b9d18-1010-4459-ae3b-2bf7994f89cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7min 2s\n",
      "Wall time: 2min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "img_dir_train = f'Images_{dataset_dir[7:-13]}/Train/'\n",
    "save_dir_train = f'Images_{dataset_dir[7:-13]}/Train/'\n",
    "img_dir_test = f'Images_{dataset_dir[7:-13]}/Test/'\n",
    "save_dir_test = f'Images_{dataset_dir[7:-13]}/Test/'\n",
    "augment_and_save_dataset(img_dir_train, save_dir_train, num_samples = 100)\n",
    "augment_and_save_dataset(img_dir_test, save_dir_test, num_samples = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a66a268d-c8d1-408c-b8be-e4ff1ef54675",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255, validation_split = 0.2)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b14b6abe-6553-4937-ab11-99a827ca2af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay_schedule(initial_lr, decay_factor=0.1, step_size=10):\n",
    "  def schedule(epoch):\n",
    "    return initial_lr * (decay_factor ** np.floor(epoch / step_size))\n",
    "    \n",
    "  return LearningRateScheduler(schedule)\n",
    "\n",
    "#os.makedirs(\"Models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7580a156-79ec-40f8-9454-b6e57630fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6546fae-c880-4cb8-bb19-c7d753845a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_vgg16 = ModelCheckpoint(\n",
    "    filepath='Models/vgg16_best_weights.h5',  \n",
    "    save_best_only=True,               \n",
    "    monitor='val_loss',                \n",
    "    verbose=1                          \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0d297a7-d843-4480-a390-5be74330ddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_inceptionv3 = ModelCheckpoint(\n",
    "    filepath='Models/inceptionv3_best_weights.h5',  \n",
    "    save_best_only=True,               \n",
    "    monitor='val_loss',                \n",
    "    verbose=1                          \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73250b36-0227-48c7-8a18-cd87c71dedcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_densenet121 = ModelCheckpoint(\n",
    "    filepath='Models/densenet121_best_weights.h5',  \n",
    "    save_best_only=True,               \n",
    "    monitor='val_loss',                \n",
    "    verbose=1                          \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "078da38a-179e-4aee-b55f-a53ec6e33018",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "learning_rate = 0.001\n",
    "decay_factor = 0.05\n",
    "step_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f389f2e3-2389-4317-adcc-93b88923ac4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 808 images belonging to 2 classes.\n",
      "Found 202 images belonging to 2 classes.\n",
      "Found 4 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "input_shape_vgg16 = (224, 224, 3)\n",
    "\n",
    "training_data_vgg16 = train_datagen.flow_from_directory(directory = img_dir_train, target_size = (224, 224), color_mode = 'rgb', batch_size = BATCH_SIZE, class_mode = 'binary', subset='training', shuffle = True, seed = 42)\n",
    "validation_data_vgg16 = train_datagen.flow_from_directory(directory = img_dir_train, target_size = (224, 224), color_mode = 'rgb', batch_size = BATCH_SIZE, class_mode = 'binary', subset='validation', shuffle = True, seed = 42)\n",
    "testing_data_vgg16 = test_datagen.flow_from_directory(directory = img_dir_test, target_size = (224, 224), color_mode = 'rgb', class_mode = 'binary', shuffle = False, seed = 42)\n",
    "\n",
    "n_steps = training_data_vgg16.samples // BATCH_SIZE\n",
    "n_val_steps = validation_data_vgg16.samples // BATCH_SIZE\n",
    "optimizer = 'Adam'\n",
    "reg_strength = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b39d0f78-5bef-403d-9244-e56ea98659c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG16\n",
    "def create_model_vgg16(input_shape, optimizer, lr, reg_strength=0.3):\n",
    "    if optimizer == 'SGD':\n",
    "        opt = SGD(learning_rate=lr)\n",
    "    elif optimizer == 'RMSprop':\n",
    "        opt = Adam(learning_rate=lr)\n",
    "    elif optimizer == 'Adam':\n",
    "        opt = RMSprop(learning_rate=lr)\n",
    "    \n",
    "    conv_base = VGG16(include_top=False,\n",
    "                      weights='imagenet',\n",
    "                      input_shape=input_shape)\n",
    "    \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    top_model = conv_base.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "    top_model = Dense(128, activation='relu', kernel_regularizer=l2(reg_strength))(top_model)\n",
    "    top_model = BatchNormalization()(top_model)\n",
    "    top_model = Dropout(0.5)(top_model)\n",
    "    top_model = Dense(64, activation='relu', kernel_regularizer=l2(reg_strength))(top_model)\n",
    "    top_model = BatchNormalization()(top_model)\n",
    "    top_model = Dropout(0.5)(top_model)\n",
    "    top_model = Dense(32, activation='relu', kernel_regularizer=l2(reg_strength))(top_model)\n",
    "    top_model = BatchNormalization()(top_model)\n",
    "    top_model = Dropout(0.5)(top_model)\n",
    "    output_layer = Dense(1, activation='sigmoid')(top_model)\n",
    "    \n",
    "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
    "    \n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecc9ff90-4210-4b5d-917e-7deb8811e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16 = create_model_vgg16(input_shape_vgg16, optimizer, learning_rate, reg_strength=reg_strength)\n",
    "lr_scheduler = step_decay_schedule(learning_rate, decay_factor, step_size)\n",
    "# history_vgg16 = model_vgg16.fit(training_data_vgg16,\n",
    "#                     validation_data=validation_data_vgg16,\n",
    "#                     steps_per_epoch=n_steps,\n",
    "#                     validation_steps=n_val_steps,\n",
    "#                     epochs=n_epochs,\n",
    "#                     callbacks=[lr_scheduler, early_stopping, model_checkpoint_vgg16],\n",
    "#                     verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b99c9b2a-350a-47ec-9559-32f79d38a34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.functional.Functional object at 0x000002BEF34B2740>\n"
     ]
    }
   ],
   "source": [
    "print(model_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3dc5a6b8-fb43-44d5-a7c4-3a953a5e4159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aug_No_0.png has been updated and saved.\n",
      "\n",
      "GettyImages-1023534494-e1685982394201.png has been updated and saved.\n",
      "\n",
      "images_2.png has been updated and saved.\n",
      "\n",
      "OOM-2023-12-26T114502.640.png has been updated and saved.\n",
      "\n",
      "paver weeds - 59.png has been updated and saved.\n",
      "\n",
      "Pavers-clean-Robert-Maxwell-for-FHM-JVedit.png has been updated and saved.\n",
      "\n",
      "phb-cleanup-6.png has been updated and saved.\n",
      "\n",
      "roof-cleaning-img.png has been updated and saved.\n",
      "\n",
      "5-Ways-to-Prevent-Weed-Growth-Between-Paving-Stones.png has been updated and saved.\n",
      "\n",
      "aug_Yes_0.png has been updated and saved.\n",
      "\n",
      "download.png has been updated and saved.\n",
      "\n",
      "download_1.png has been updated and saved.\n",
      "\n",
      "g1YsC.png has been updated and saved.\n",
      "\n",
      "images.png has been updated and saved.\n",
      "\n",
      "images_1.png has been updated and saved.\n",
      "\n",
      "paver weeds - 85.png has been updated and saved.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img_dir_test = f'Images_{dataset_dir[7:-13]}/Test/'\n",
    "\n",
    "classes = os.listdir(img_dir_test)\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(img_dir_test, class_name)\n",
    "    for filename in os.listdir(class_path):\n",
    "        if filename.endswith('png'):\n",
    "            img_path = os.path.join(class_path, filename)\n",
    "            img = tf.io.read_file(img_path)\n",
    "            img = tf.image.decode_png(img, channels=3)\n",
    "            img = tf.cast(img, tf.float32)\n",
    "            max_val = tf.reduce_max(img)\n",
    "            img_normalized = (img / max_val) * 255\n",
    "        \n",
    "            tf.keras.utils.save_img(img_path, img_normalized)\n",
    "            print(f\"{filename} has been updated and saved.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b460b3b-5c18-4a86-8dda-8b85d972a4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 122ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.50      1.00      0.67         2\n",
      "         Yes       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50         4\n",
      "   macro avg       0.25      0.50      0.33         4\n",
      "weighted avg       0.25      0.50      0.33         4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rushi\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Rushi\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Rushi\\anaconda3\\envs\\py310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "test_steps = 1\n",
    "testing_data_vgg16.reset()\n",
    "\n",
    "model_vgg16.load_weights('Models/vgg16_best_weights.h5')\n",
    "\n",
    "predictions_vgg16 = model_vgg16.predict(testing_data_vgg16, steps=test_steps, verbose=1)\n",
    "\n",
    "predicted_classes_vgg16 = np.where(predictions_vgg16 > 0.5, 1, 0)\n",
    "\n",
    "true_classes = testing_data_vgg16.classes\n",
    "\n",
    "true_classes = true_classes[:len(predicted_classes_vgg16)]\n",
    "\n",
    "report_vgg16 = classification_report(true_classes, predicted_classes_vgg16, target_names=testing_data_vgg16.class_indices)\n",
    "print(report_vgg16)\n",
    "\n",
    "fpr_vgg16, tpr_vgg16, thresholds_vgg16 = roc_curve(true_classes, predictions_vgg16)\n",
    "roc_auc_vgg16 = auc(fpr_vgg16, tpr_vgg16)\n",
    "\n",
    "cm_vgg16 = confusion_matrix(true_classes, predicted_classes_vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4df9b1fb-eb25-4c12-81e4-957fec780c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26077202],\n",
       "       [0.00131006],\n",
       "       [0.29917446],\n",
       "       [0.0087604 ]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9af3f4d6-65ad-4d39-a639-ac94d4d2cb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "58b4fed8-9ec3-4ba8-8317-3a9ba21c669d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_classes_vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d07ae94f-1b3a-4def-a541-9258d0eba2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 Score is: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"The F1 Score is: {f1_score(true_classes, predicted_classes_vgg16)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe062b-3dff-4d42-8a6a-0a2748d0d742",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2 \n",
    "plt.plot(fpr_vgg16, tpr_vgg16, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc_vgg16)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8fa939-38c1-430f-826f-1df17dd96359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66578e4-e381-4d76-8f72-4decb758e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape_inceptionv3 = (299, 299, 3)\n",
    "\n",
    "training_data_inceptionv3 = train_datagen.flow_from_directory(directory = img_dir_train, target_size = (299, 299), color_mode = 'rgb', batch_size = BATCH_SIZE, class_mode = 'binary', subset='training', shuffle = True, seed = 42)\n",
    "validation_data_inceptionv3 = train_datagen.flow_from_directory(directory = img_dir_train, target_size = (299, 299), color_mode = 'rgb', batch_size = BATCH_SIZE, class_mode = 'binary', subset='validation', shuffle = True, seed = 42)\n",
    "testing_data_inceptionv3 = test_datagen.flow_from_directory(directory = img_dir_test, target_size = (299, 299), color_mode = 'rgb', class_mode = 'binary', shuffle = False, seed = 42)\n",
    "\n",
    "n_steps = training_data_inceptionv3.samples // BATCH_SIZE\n",
    "n_val_steps = validation_data_inceptionv3.samples // BATCH_SIZE\n",
    "\n",
    "optimizer = 'Adam'\n",
    "reg_strength = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ea4fe-9617-49ff-8b5d-d5bf0de3533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inception-v3\n",
    "def create_model_inceptionv3(input_shape, optimizer, lr, reg_strength=0.3):\n",
    "    if optimizer == 'SGD':\n",
    "        opt = SGD(learning_rate=lr)\n",
    "    elif optimizer == 'RMSprop':\n",
    "        opt = Adam(learning_rate=lr)\n",
    "    elif optimizer == 'Adam':\n",
    "        opt = RMSprop(learning_rate=lr)\n",
    "    \n",
    "    conv_base = InceptionV3(include_top=False,\n",
    "                      weights='imagenet',\n",
    "                      input_shape=input_shape)\n",
    "    \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    top_model = conv_base.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "    top_model = Dense(128, activation='relu', kernel_regularizer=l2(reg_strength))(top_model)\n",
    "    top_model = BatchNormalization()(top_model)\n",
    "    top_model = Dropout(0.5)(top_model)\n",
    "    top_model = Dense(64, activation='relu', kernel_regularizer=l2(reg_strength))(top_model)\n",
    "    top_model = BatchNormalization()(top_model)\n",
    "    top_model = Dropout(0.5)(top_model)\n",
    "    top_model = Dense(32, activation='relu', kernel_regularizer=l2(reg_strength))(top_model)\n",
    "    top_model = BatchNormalization()(top_model)\n",
    "    top_model = Dropout(0.5)(top_model)\n",
    "    output_layer = Dense(1, activation='sigmoid')(top_model)\n",
    "    \n",
    "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
    "    \n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9af6c6-a352-4eb8-9978-df81085f9675",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inceptionv3 = create_model_inceptionv3(input_shape_inceptionv3, optimizer, learning_rate, reg_strength=reg_strength)\n",
    "lr_scheduler = step_decay_schedule(learning_rate, decay_factor, step_size)\n",
    "history_inceptionv3 = model_inceptionv3.fit(training_data_inceptionv3,\n",
    "                    validation_data=validation_data_inceptionv3,\n",
    "                    steps_per_epoch=n_steps,\n",
    "                    validation_steps=n_val_steps,\n",
    "                    epochs=n_epochs,\n",
    "                    callbacks=[lr_scheduler, early_stopping, model_checkpoint_inceptionv3],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5845f2-ba4b-4a0c-b902-e8a09e6ac554",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps = 1\n",
    "testing_data_inceptionv3.reset()\n",
    "\n",
    "model_inceptionv3.load_weights('Models/inceptionv3_best_weights.h5')\n",
    "\n",
    "predictions_inceptionv3 = model_inceptionv3.predict(testing_data_inceptionv3, steps=test_steps, verbose=1)\n",
    "\n",
    "predicted_classes_inceptionv3 = np.where(predictions_inceptionv3 > 0.5, 1, 0)\n",
    "\n",
    "true_classes = testing_data_inceptionv3.classes\n",
    "\n",
    "true_classes = true_classes[:len(predicted_classes_inceptionv3)]\n",
    "\n",
    "report_inceptionv3 = classification_report(true_classes, predicted_classes_inceptionv3, target_names=testing_data_inceptionv3.class_indices)\n",
    "print(report_inceptionv3)\n",
    "\n",
    "fpr_inceptionv3, tpr_inceptionv3, thresholds_inceptionv3 = roc_curve(true_classes, predictions_inceptionv3)\n",
    "roc_auc_inceptionv3 = auc(fpr_inceptionv3, tpr_inceptionv3)\n",
    "\n",
    "cm_inceptionv3 = confusion_matrix(true_classes, predicted_classes_inceptionv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8676cf5d-38c1-4f45-a1f7-75b945c94d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The F1 Score is: {f1_score(true_classes, predicted_classes_inceptionv3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb13f913-c154-4839-a92b-1448c8b995b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2 \n",
    "plt.plot(fpr_inceptionv3, tpr_inceptionv3, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc_inceptionv3)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4ddba3-21fa-4ae5-a240-9a2dd57db7df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4c67e2-6701-444e-8f56-ec9baf30853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape_densenet121 = (224, 224, 3)\n",
    "\n",
    "training_data_densenet121 = train_datagen.flow_from_directory(directory = img_dir_train, target_size = (224, 224), color_mode = 'rgb', batch_size = BATCH_SIZE, class_mode = 'binary', subset='training', shuffle = True, seed = 42)\n",
    "validation_data_densenet121 = train_datagen.flow_from_directory(directory = img_dir_train, target_size = (224, 224), color_mode = 'rgb', batch_size = BATCH_SIZE, class_mode = 'binary', subset='validation', shuffle = True, seed = 42)\n",
    "testing_data_densenet121 = test_datagen.flow_from_directory(directory = img_dir_test, target_size = (224, 224), color_mode = 'rgb', class_mode = 'binary', shuffle = False, seed = 42)\n",
    "\n",
    "n_steps = training_data_densenet121.samples // BATCH_SIZE\n",
    "n_val_steps = validation_data_densenet121.samples // BATCH_SIZE\n",
    "\n",
    "optimizer = 'SGD'\n",
    "reg_strength = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1272897-9bc6-44c0-acbe-098c9f96b9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DenseNet\n",
    "def create_model_densenet121(input_shape, optimizer, lr, reg_strength=0.3):\n",
    "    if optimizer == 'SGD':\n",
    "        opt = SGD(learning_rate=lr)\n",
    "    elif optimizer == 'RMSprop':\n",
    "        opt = Adam(learning_rate=lr)\n",
    "    elif optimizer == 'Adam':\n",
    "        opt = RMSprop(learning_rate=lr)\n",
    "    \n",
    "    conv_base = DenseNet121(include_top=False,\n",
    "                      weights='imagenet',\n",
    "                      input_shape=input_shape)\n",
    "    \n",
    "    for layer in conv_base.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    top_model = conv_base.output\n",
    "    top_model = GlobalAveragePooling2D()(top_model)\n",
    "    top_model = Dense(128, activation='relu', kernel_regularizer=l2(reg_strength))(top_model)\n",
    "    top_model = BatchNormalization()(top_model)\n",
    "    top_model = Dropout(0.5)(top_model)\n",
    "    top_model = Dense(64, activation='relu', kernel_regularizer=l2(reg_strength))(top_model)\n",
    "    top_model = BatchNormalization()(top_model)\n",
    "    top_model = Dropout(0.5)(top_model)    \n",
    "    top_model = Dense(32, activation='relu', kernel_regularizer=l2(reg_strength))(top_model)\n",
    "    top_model = BatchNormalization()(top_model)\n",
    "    top_model = Dropout(0.5)(top_model)\n",
    "    output_layer = Dense(1, activation='sigmoid')(top_model)\n",
    "    \n",
    "    model = Model(inputs=conv_base.input, outputs=output_layer)\n",
    "    \n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c47b52e-dc49-44c3-ab76-bd57212f9634",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_densenet121 = create_model_densenet121(input_shape_densenet121, optimizer, learning_rate, reg_strength=reg_strength)\n",
    "lr_scheduler = step_decay_schedule(learning_rate, decay_factor, step_size)\n",
    "history_densenet121 = model_densenet121.fit(training_data_densenet121,\n",
    "                    validation_data=validation_data_densenet121,\n",
    "                    steps_per_epoch=n_steps,\n",
    "                    validation_steps=n_val_steps,\n",
    "                    epochs=n_epochs,\n",
    "                    callbacks=[lr_scheduler, early_stopping, model_checkpoint_densenet121],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d31d865-6e3f-47e6-a00c-98f6dd21ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps = 1\n",
    "testing_data_densenet121.reset()\n",
    "\n",
    "model_densenet121.load_weights('Models/densenet121_best_weights.h5')\n",
    "\n",
    "predictions_densenet121 = model_densenet121.predict(testing_data_densenet121, steps=test_steps, verbose=1)\n",
    "\n",
    "predicted_classes_densenet121 = np.where(predictions_densenet121 > 0.5, 1, 0)\n",
    "\n",
    "true_classes = testing_data_densenet121.classes\n",
    "\n",
    "true_classes = true_classes[:len(predicted_classes_densenet121)]\n",
    "\n",
    "report_densenet121 = classification_report(true_classes, predicted_classes_densenet121, target_names=testing_data_densenet121.class_indices)\n",
    "print(report_densenet121)\n",
    "\n",
    "fpr_densenet121, tpr_densenet121, thresholds = roc_curve(true_classes, predictions_densenet121)\n",
    "roc_auc_densenet121 = auc(fpr_densenet121, tpr_densenet121)\n",
    "\n",
    "cm_densenet121 = confusion_matrix(true_classes, predicted_classes_densenet121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb1fff3-f8e7-4f6e-870a-f222e54efae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The F1 Score is: {f1_score(true_classes, predicted_classes_densenet121)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18672903-23cf-4080-8195-6d0be95b2b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2 \n",
    "plt.plot(fpr_densenet121, tpr_densenet121, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc_densenet121)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051515d6-02b1-4ac0-bad4-d5e51b1c5611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8848c59a-9476-45d1-a755-43d5ab4b7073",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_ensemble = train_datagen.flow_from_directory(directory = img_dir_train, target_size = (224, 224), color_mode = 'rgb', batch_size = BATCH_SIZE, class_mode = 'binary', subset='training', shuffle = True, seed = 42)\n",
    "validation_data_ensemble = train_datagen.flow_from_directory(directory = img_dir_train, target_size = (224, 224), color_mode = 'rgb', batch_size = BATCH_SIZE, class_mode = 'binary', subset='validation', shuffle = True, seed = 42)\n",
    "testing_data_ensemble = test_datagen.flow_from_directory(directory = img_dir_test, target_size = (224, 224), color_mode = 'rgb', class_mode = 'binary', shuffle = False, seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba94d64-e99d-464f-90ee-bc7c5a81de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg16 = load_model('Models/vgg16_best_weights.h5')\n",
    "model_inception = load_model('Models/inceptionv3_best_weights.h5')\n",
    "model_densenet = load_model('Models/densenet121_best_weights.h5')\n",
    "\n",
    "for model in [model_vgg16, model_inception, model_densenet]:\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "input_tensor = Input(shape=(224, 224, 3))\n",
    "\n",
    "vgg16_features = model_vgg16(input_tensor)\n",
    "inception_features = model_inception(input_tensor)\n",
    "densenet_features = model_densenet(input_tensor)\n",
    "\n",
    "concatenated_features = Concatenate()([vgg16_features, inception_features, densenet_features])\n",
    "\n",
    "output = Dense(1, activation='sigmoid')(concatenated_features)\n",
    "\n",
    "ensemble_model = Model(inputs=input_tensor, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e17d813-a918-4731-83cc-f9f7458616b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy'])\n",
    "history = ensemble_model.fit(training_data_ensemble,\n",
    "                             epochs = 20,\n",
    "                             validation_data = validation_data_ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa367c66-7361-48e5-8c6b-86efc8eb1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Loss Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Accuracy Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d44887a-1a24-418e-ba7e-ec4cd743d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val_loss = min(history.history['val_loss'])\n",
    "min_loss_index = history.history['val_loss'].index(min_val_loss)\n",
    "min_loss_acc = history.history['val_accuracy'][min_loss_index]\n",
    "\n",
    "print(\"\\nTraining results:\")\n",
    "print(\"\\tMin val loss {:.4f} was achieved during iteration #{}\".format(min_val_loss, min_loss_index + 1))\n",
    "print(\"\\tVal accuracy during min val loss is {:.4f}\".format(min_loss_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
